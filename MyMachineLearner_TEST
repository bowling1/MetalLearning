import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor

file1_path = 'Metal Sheet 2 - Sheet1.csv'

data = pd.read_csv(file1_path, encoding="ISO-8859-1")

badcolumns = [0,1,2,3,4,10,11,12,13,14,15,17,18]
badcolumns1 = []
for i in range(19, 36):
	badcolumns1.append(i)

data.drop(data.columns[badcolumns1],axis=1,inplace=True)
data.drop(data.columns[badcolumns],axis=1,inplace=True)

cat_features = [data['Region'],data['Continent'],data['Subgenre 1']]

one_hot1 = pd.get_dummies(cat_features[0])
one_hot2 = pd.get_dummies(cat_features[1])
one_hot3 = pd.get_dummies(cat_features[2])

OH_column1 = list(one_hot1.columns)
OH_column2 = list(one_hot2.columns)
OH_column3 = list(one_hot3.columns)

data = pd.concat([data, one_hot1], axis=1)
data = pd.concat([data, one_hot2], axis=1)
data = pd.concat([data, one_hot3], axis=1)
data.drop(data.columns[[0,1,4]], axis=1, inplace=True)

y = data.Relistenability
features = data.columns
x = data[features]

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=1)

def get_mae(max_leaf, train_x, train_y, val_x, val_y):
	model1 = RandomForestRegressor(max_leaf_nodes=max_leaf, random_state=1)
	model1.fit(train_x, train_y)
	predict = model1.predict(val_x)
	val_mae = mean_absolute_error(predict, val_y)
	return val_mae
val_mae_top = 5
tree_top = 0
for i in range(5,100, 1):
	val_mae = get_mae(i, train_x, train_y, val_x, val_y)
	if val_mae < val_mae_top:
		val_mae_top = val_mae
		tree_top = i

print(val_mae_top)
print(tree_top)
